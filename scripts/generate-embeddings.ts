/**
 * ë¬¸ì„œ ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸
 *
 * content/posts/*.md íŒŒì¼ì„ ì½ì–´ì„œ:
 * 1. ì²­í¬ë¡œ ë¶„í• 
 * 2. OpenAIë¡œ ì„ë² ë”© ìƒì„±
 * 3. Supabaseì— ì €ì¥
 */

import 'dotenv/config';
import fs from 'fs';
import path from 'path';
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';
import matter from 'gray-matter';

// í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY!;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY!;

if (!SUPABASE_URL || !SUPABASE_KEY || !OPENAI_API_KEY) {
  console.error('âŒ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  process.exit(1);
}

const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

// ì²­í¬ í¬ê¸° ì„¤ì • (í† í° ë‹¨ìœ„)
// Anthropic ê¶Œì¥: 800 í† í° (ì„±ëŠ¥ ìµœì í™”)
const CHUNK_SIZE = 800; // ëŒ€ëµ 800 í† í° (ì•½ 600-700 ë‹¨ì–´)
const CHUNK_OVERLAP = 80; // ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„ (10% overlap)

/**
 * í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
 */
function splitIntoChunks(text: string, chunkSize: number = CHUNK_SIZE): string[] {
  const words = text.split(/\s+/);
  const chunks: string[] = [];

  for (let i = 0; i < words.length; i += chunkSize - CHUNK_OVERLAP) {
    const chunk = words.slice(i, i + chunkSize).join(' ');
    if (chunk.trim()) {
      chunks.push(chunk.trim());
    }
  }

  return chunks;
}

/**
 * ì„ë² ë”© ìƒì„±
 */
async function generateEmbedding(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text,
  });

  return response.data[0].embedding;
}

/**
 * Contextual Retrieval: ì²­í¬ì— ëŒ€í•œ ë§¥ë½ ìƒì„±
 *
 * OpenAI GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì²­í¬ì— ëŒ€í•œ ë§¥ë½ì„ ìƒì„±í•©ë‹ˆë‹¤.
 * Anthropic Contextual Retrieval ë°©ì‹ ì ìš©
 * (ë¹„ìš© ìµœì í™”: Claude ëŒ€ë¹„ 82% ì ˆê°)
 */
async function generateContext(
  fullDocument: string,
  chunk: string,
  metadata: {
    title: string;
    type: string;
    tags?: string[];
    category?: string;
  }
): Promise<string> {
  const typeLabel = metadata.type === 'article' ? 'ê³µê°œ ë¸”ë¡œê·¸ ê¸€' :
                    metadata.type === 'training' ? 'í•™ìŠµ ìë£Œ' : 'ë…¸íŠ¸';

  const prompt = `<document>
Title: "${metadata.title}"
Type: ${typeLabel}
Category: ${metadata.category || 'general'}
Tags: ${metadata.tags?.join(', ') || 'none'}

Full Content:
${fullDocument}
</document>

Situate the following chunk within the overall document context.
Provide 100-150 characters of concise contextual description in Korean that explains:
- What this chunk is about
- How it relates to the document's main theme
- Key concepts or decisions discussed

<chunk>
${chunk}
</chunk>

Context (Korean, 100-150 chars):`;

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{
        role: 'user',
        content: prompt
      }],
      max_tokens: 150, // 100 â†’ 150 (ë” ìƒì„¸í•œ ë§¥ë½)
      temperature: 0,
    });

    const context = response.choices[0]?.message?.content?.trim() || '';
    return context;
  } catch (error) {
    console.error('  âš ï¸  ë§¥ë½ ìƒì„± ì‹¤íŒ¨, ì›ë³¸ ì²­í¬ë§Œ ì‚¬ìš©:', error);
    return '';
  }
}

/**
 * ë‹¨ì¼ ë¬¸ì„œ ì²˜ë¦¬
 */
async function processDocument(filePath: string) {
  console.log(`\nğŸ“„ ì²˜ë¦¬ ì¤‘: ${filePath}`);

  // íŒŒì¼ ì½ê¸°
  const fileContent = fs.readFileSync(filePath, 'utf-8');
  const { data: frontmatter, content } = matter(fileContent);

  // ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
  const title = frontmatter.title || path.basename(filePath, '.md');

  // Type ê°ì§€: training > article > note
  let type: string;
  if (filePath.includes('/training/')) {
    type = 'training';
  } else if (filePath.includes('/posts/')) {
    type = 'article';
  } else {
    type = frontmatter.type || 'note';
  }

  const tags = frontmatter.tags || [];
  const category = frontmatter.category || 'general';
  const priority = frontmatter.priority || 'medium';
  const visibility = frontmatter.visibility || (type === 'training' ? 'private' : 'public');
  const publishedDate = frontmatter.date || null;

  // ì²­í¬ ë¶„í• 
  const chunks = splitIntoChunks(content);
  console.log(`  â†’ ${chunks.length}ê°œì˜ ì²­í¬ë¡œ ë¶„í• `);

  // ê° ì²­í¬ ì²˜ë¦¬
  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];

    try {
      // 1. Contextual Retrieval: ë§¥ë½ ìƒì„±
      const context = await generateContext(content, chunk, { title, type, tags, category });

      // 2. ë§¥ë½ + ì²­í¬ ê²°í•©
      const contentWithContext = context
        ? `${context}\n\n${chunk}`
        : chunk;

      // 3. ë§¥ë½ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ë¡œ ì„ë² ë”© ìƒì„±
      const embedding = await generateEmbedding(contentWithContext);

      // 4. Supabaseì— ì €ì¥ (ì›ë³¸ contentì™€ content_with_context ëª¨ë‘ ì €ì¥)
      // URL ìƒì„±: trainingì€ null, postsëŠ” ë§í¬
      const url = type === 'training' ? null :
                  type === 'article' ? `/posts/${path.basename(filePath, '.md')}` :
                  null;

      const { error } = await supabase.from('documents').insert({
        content: chunk, // ì›ë³¸ ì²­í¬ (ì‚¬ìš©ìì—ê²Œ í‘œì‹œìš©)
        content_with_context: contentWithContext, // ë§¥ë½ í¬í•¨ (ê²€ìƒ‰/ì„ë² ë”©ìš©)
        embedding,
        title: chunks.length > 1 ? `${title} (part ${i + 1}/${chunks.length})` : title,
        type,
        url,
        tags,
        published_date: publishedDate,
        metadata: {
          source_file: filePath,
          chunk_index: i,
          total_chunks: chunks.length,
          context_length: context.length,
          category,
          priority,
          visibility,
          frontmatter,
        },
      });

      if (error) {
        console.error(`  âŒ ì²­í¬ ${i + 1} ì €ì¥ ì‹¤íŒ¨:`, error.message);
      } else {
        console.log(`  âœ… ì²­í¬ ${i + 1}/${chunks.length} ì €ì¥ ì™„ë£Œ`);
      }

      // Rate limiting ë°©ì§€ (OpenAI API)
      await new Promise(resolve => setTimeout(resolve, 100));

    } catch (error) {
      console.error(`  âŒ ì²­í¬ ${i + 1} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
    }
  }
}

/**
 * ë°°ì—´ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ëŠ” í—¬í¼ í•¨ìˆ˜
 */
function chunkArray<T>(array: T[], size: number): T[][] {
  const chunks: T[][] = [];
  for (let i = 0; i < array.length; i += size) {
    chunks.push(array.slice(i, i + size));
  }
  return chunks;
}

/**
 * ë©”ì¸ í•¨ìˆ˜
 */
async function main() {
  console.log('ğŸš€ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì‹œì‘\n');

  const files: string[] = [];

  // 1. intro.md ì¶”ê°€ (ìµœìš°ì„ )
  const introFile = path.join(process.cwd(), 'content', 'intro.md');
  if (fs.existsSync(introFile)) {
    files.push(introFile);
    console.log('âœ“ intro.md ì¶”ê°€');
  }

  // 2. opinions.md ì¶”ê°€ (ì˜ì‚¬ê²°ì • ì›ì¹™)
  const opinionsFile = path.join(process.cwd(), 'content', 'opinions.md');
  if (fs.existsSync(opinionsFile)) {
    files.push(opinionsFile);
    console.log('âœ“ opinions.md ì¶”ê°€');
  }

  // 3. content/posts (ê³µê°œ ë¸”ë¡œê·¸ ê¸€)
  const postsDir = path.join(process.cwd(), 'content', 'posts');
  if (fs.existsSync(postsDir)) {
    const postFiles = fs.readdirSync(postsDir)
      .filter(file => file.endsWith('.md') && file !== 'README.md')
      .map(file => path.join(postsDir, file));
    files.push(...postFiles);
    console.log(`âœ“ posts: ${postFiles.length}ê°œ íŒŒì¼ ì¶”ê°€`);
  }

  // 4. content/training (AI í•™ìŠµ ì „ìš©)
  const trainingDir = path.join(process.cwd(), 'content', 'training');
  if (fs.existsSync(trainingDir)) {
    const trainingFiles = fs.readdirSync(trainingDir)
      .filter(file => file.endsWith('.md') && file !== 'README.md')
      .map(file => path.join(trainingDir, file));
    files.push(...trainingFiles);
    console.log(`âœ“ training: ${trainingFiles.length}ê°œ íŒŒì¼ ì¶”ê°€`);
  }

  console.log(`\nğŸ“š ì´ ${files.length}ê°œì˜ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n`);

  if (files.length === 0) {
    console.log('âš ï¸  ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.');
    return;
  }

  // ë°°ì¹˜ ì²˜ë¦¬ (5ê°œì”© ë³‘ë ¬)
  const batches = chunkArray(files, 5);
  let processed = 0;

  for (let i = 0; i < batches.length; i++) {
    const batch = batches[i];
    console.log(`\nğŸ“¦ ë°°ì¹˜ ${i + 1}/${batches.length} ì²˜ë¦¬ ì¤‘... (${batch.length}ê°œ íŒŒì¼)`);

    await Promise.all(batch.map(async (file) => {
      await processDocument(file);
      processed++;
    }));

    console.log(`   â†’ ì§„í–‰ë¥ : ${processed}/${files.length} (${Math.round(processed/files.length*100)}%)`);

    // ë°°ì¹˜ ê°„ ì•½ê°„ì˜ ë”œë ˆì´ (rate limiting)
    if (i < batches.length - 1) {
      await new Promise(resolve => setTimeout(resolve, 500));
    }
  }

  console.log('\nâœ¨ ëª¨ë“  ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!');
  console.log(`ğŸ“Š ì´ ${processed}ê°œ íŒŒì¼ ì„ë² ë”© ìƒì„± ì™„ë£Œ`);
}

main().catch(console.error);
