/**
 * RAG ì±„íŒ… API
 *
 * ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ:
 * 1. ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
 * 2. Supabaseì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
 * 3. GPT-4ë¡œ ë‹µë³€ ìƒì„±
 */

import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

interface Message {
  role: 'user' | 'assistant';
  content: string;
}

interface ChatRequest {
  message: string;
  history?: Message[];
}

interface Source {
  id: string;
  title: string;
  content: string;
  url: string | null;
  similarity: number;
}

interface ChatResponse {
  message: string;
  sources: Source[];
}

export async function POST(req: NextRequest) {
  try {
    const { message, history = [] }: ChatRequest = await req.json();

    if (!message || !message.trim()) {
      return NextResponse.json(
        { error: 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.' },
        { status: 400 }
      );
    }

    console.log('ğŸ“© ì§ˆë¬¸:', message);

    // 1. ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    const embeddingResponse = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: message,
    });
    const queryEmbedding = embeddingResponse.data[0].embedding;

    // 2. Supabase ë²¡í„° ê²€ìƒ‰
    const { data: documents, error: searchError } = await supabase.rpc(
      'match_documents',
      {
        query_embedding: queryEmbedding,
        match_threshold: 0.2, // 20% ì´ìƒ ìœ ì‚¬ë„
        match_count: 5,
      }
    );

    if (searchError) {
      console.error('ê²€ìƒ‰ ì—ëŸ¬:', searchError);
      return NextResponse.json(
        { error: 'ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
        { status: 500 }
      );
    }

    console.log(`ğŸ” ${documents?.length || 0}ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬`);

    // 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    const context = documents && documents.length > 0
      ? documents
          .map(
            (doc: any, i: number) => `
[ì¶œì²˜ ${i + 1}]
ì œëª©: ${doc.title || 'ì œëª© ì—†ìŒ'}
ë‚´ìš©: ${doc.content}
---`
          )
          .join('\n')
      : 'ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';

    // 4. GPT-4ë¡œ ë‹µë³€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)
    const systemPrompt = `ë‹¹ì‹ ì€ William Jungì˜ ê¸€ê³¼ í”„ë¡œì íŠ¸ë¥¼ í•™ìŠµí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì•„ë˜ ì œê³µëœ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ê·œì¹™:
- ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” í•´ë‹¹ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì†”ì§íˆ ë§í•˜ì„¸ìš”
- ë‹µë³€ ì‹œ ì–´ëŠ ì¶œì²˜ì—ì„œ ë‚˜ì˜¨ ì •ë³´ì¸ì§€ [ì¶œì²˜ N] í˜•íƒœë¡œ í‘œì‹œí•˜ì„¸ìš”
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”

ì œê³µëœ ë¬¸ì„œ:
${context}`;

    const messages: any[] = [
      { role: 'system', content: systemPrompt },
      ...history.slice(-6), // ìµœê·¼ 3í„´ë§Œ ìœ ì§€
      { role: 'user', content: message },
    ];

    // 5. ì¶œì²˜ ì •ë³´ êµ¬ì„±
    const sources: Source[] = documents
      ? documents.map((doc: any) => ({
          id: doc.id,
          title: doc.title || 'ì œëª© ì—†ìŒ',
          content: doc.content.substring(0, 200) + '...',
          url: doc.url,
          similarity: doc.similarity,
        }))
      : [];

    // 6. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
    const encoder = new TextEncoder();

    const stream = new ReadableStream({
      async start(controller) {
        try {
          // ì²« ë²ˆì§¸ ì²­í¬: sources ì •ë³´ ì „ì†¡
          controller.enqueue(
            encoder.encode(JSON.stringify({ type: 'sources', data: sources }) + '\n')
          );

          // ë‘ ë²ˆì§¸: OpenAI ìŠ¤íŠ¸ë¦¼ ì‹œì‘
          const completion = await openai.chat.completions.create({
            model: 'gpt-4o-mini',
            messages,
            temperature: 0.7,
            max_tokens: 1000,
            stream: true, // ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œì„±í™”
          });

          // OpenAI ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
          for await (const chunk of completion) {
            const content = chunk.choices[0]?.delta?.content;
            if (content) {
              controller.enqueue(
                encoder.encode(JSON.stringify({ type: 'content', data: content }) + '\n')
              );
            }
          }

          // ì™„ë£Œ ì‹ í˜¸
          controller.enqueue(
            encoder.encode(JSON.stringify({ type: 'done' }) + '\n')
          );

          console.log('âœ… ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± ì™„ë£Œ');
          controller.close();

        } catch (error) {
          console.error('ìŠ¤íŠ¸ë¦¬ë° ì—ëŸ¬:', error);
          controller.enqueue(
            encoder.encode(JSON.stringify({
              type: 'error',
              message: error instanceof Error ? error.message : 'ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
            }) + '\n')
          );
          controller.close();
        }
      }
    });

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    });

  } catch (error) {
    console.error('Chat API ì—ëŸ¬:', error);
    return NextResponse.json(
      { error: 'ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    );
  }
}
