import { NextRequest, NextResponse } from 'next/server';
import { supabaseAdmin } from '@/lib/db/supabase';
import { fetchRSSFeed } from '@/lib/scraping/rss-fetcher';
import { extractArticleContent } from '@/lib/extraction/content-extractor';

export async function GET(request: NextRequest) {
  console.log('ğŸš€ Starting simple RSS scraping...');

  try {
    // 1. ë‹¨ì¼ RSS í”¼ë“œë§Œ í…ŒìŠ¤íŠ¸
    const feedUrl = 'https://techcrunch.com/feed/';
    console.log(`ğŸ“¡ Fetching: ${feedUrl}`);

    // 2. RSS ê°€ì ¸ì˜¤ê¸°
    const articles = await fetchRSSFeed(feedUrl);
    console.log(`ğŸ“° Found ${articles.length} articles`);

    if (articles.length === 0) {
      return NextResponse.json({
        success: false,
        message: 'No articles found in RSS feed',
      });
    }

    // 3. ì²« 3ê°œ ê¸°ì‚¬ë§Œ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©)
    const articlesToProcess = articles.slice(0, 3);
    const results = [];

    for (const article of articlesToProcess) {
      try {
        // ì¤‘ë³µ ì²´í¬
        const { data: existing } = await supabaseAdmin
          .from('articles')
          .select('id')
          .eq('url', article.link)
          .single();

        if (existing) {
          results.push({
            title: article.title,
            status: 'skipped',
            reason: 'Already exists',
          });
          continue;
        }

        // ì „ì²´ ë³¸ë¬¸ ì¶”ì¶œ
        let fullContent = article.content || article.title;
        let thumbnail = article.thumbnail;
        let extractionStatus = 'rss';

        // RSS ìš”ì•½ë³¸ì´ ì§§ìœ¼ë©´ ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ì „ì²´ ë³¸ë¬¸ ì¶”ì¶œ
        if (fullContent.length < 500) {
          console.log(`ğŸ“– Extracting full content for: ${article.title.substring(0, 50)}...`);
          try {
            const extracted = await extractArticleContent(article.link);

            if (extracted && extracted.content && extracted.content.length > fullContent.length) {
              fullContent = extracted.content;
              thumbnail = extracted.thumbnail || thumbnail;
              extractionStatus = 'extracted';
              console.log(`âœ… Extracted ${extracted.content.length} chars`);
            }
          } catch (extractError) {
            console.log(`âš ï¸ Extraction failed, using RSS content`);
          }
        }

        // DB ì €ì¥
        const { data: saved, error } = await supabaseAdmin
          .from('articles')
          .insert({
            url: article.link,
            title: article.title,
            content: fullContent,
            excerpt: fullContent.substring(0, 300),
            thumbnail_url: thumbnail,
            source: 'TechCrunch',
            published_at: article.pubDate,
            status: 'pending',
          })
          .select()
          .single();

        if (error) {
          console.error('Insert error:', error);
          results.push({
            title: article.title,
            status: 'failed',
            error: error.message,
          });
        } else {
          results.push({
            title: article.title,
            status: 'saved',
            id: saved.id,
            contentLength: fullContent.length,
            extractionStatus,
          });
        }
      } catch (err) {
        console.error('Article processing error:', err);
        results.push({
          title: article.title,
          status: 'error',
          error: err instanceof Error ? err.message : 'Unknown error',
        });
      }
    }

    return NextResponse.json({
      success: true,
      totalFound: articles.length,
      processed: results.length,
      results,
    });
  } catch (error) {
    console.error('âŒ Scraping failed:', error);
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error',
    }, { status: 500 });
  }
}