import { NextRequest, NextResponse } from 'next/server';
import { supabaseAdmin } from '@/lib/db/supabase';
import { fetchRSSFeed, POPULAR_RSS_FEEDS } from '@/lib/scraping/rss-fetcher';
import { extractArticleContent } from '@/lib/extraction/content-extractor';

/**
 * Cron Job: RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° DB ì €ì¥
 * ìŠ¤ì¼€ì¤„: ë§¤ 2ì‹œê°„ë§ˆë‹¤
 */
export async function GET(request: NextRequest) {
  // Cron secret ê²€ì¦ (í”„ë¡œë•ì…˜ì—ì„œ í™œì„±í™”)
  // const authHeader = request.headers.get('authorization');
  // if (authHeader !== `Bearer ${process.env.CRON_SECRET}`) {
  //   return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  // }

  console.log('ğŸš€ Starting RSS scraping job...');

  try {
    // ëª¨ë“  RSS í”¼ë“œ ìˆ˜ì§‘
    const allFeeds = [
      ...POPULAR_RSS_FEEDS.technology,
      ...POPULAR_RSS_FEEDS.general,
    ];

    let totalArticles = 0;
    let newArticles = 0;

    for (const feedUrl of allFeeds) {
      try {
        console.log(`ğŸ“¡ Fetching feed: ${feedUrl}`);

        const articles = await fetchRSSFeed(feedUrl);

        for (const article of articles) {
          // 24ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ë§Œ ì²˜ë¦¬
          const pubDate = article.pubDate ? new Date(article.pubDate) : null;
          const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000);

          if (pubDate && pubDate < oneDayAgo) {
            continue; // ì˜¤ë˜ëœ ê¸°ì‚¬ ê±´ë„ˆë›°ê¸°
          }

          // DBì— ê¸°ì‚¬ ì €ì¥ (ì¤‘ë³µ í™•ì¸)
          const { data: existingArticle } = await supabaseAdmin
            .from('articles')
            .select('id')
            .eq('url', article.link)
            .single();

          if (existingArticle) {
            continue; // ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê¸°ì‚¬
          }

          // ì½˜í…ì¸  ì¶”ì¶œ (ì„ íƒì  - RSSì— ì „ë¬¸ì´ ì—†ëŠ” ê²½ìš°)
          let fullContent = article.fullContent || article.content;
          let thumbnail = article.thumbnail;

          // RSSì— ì „ë¬¸ì´ ì—†ìœ¼ë©´ ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ì¶”ì¶œ (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¼ë‹¨ skip)
          // if (!fullContent || fullContent.length < 200) {
          //   const extracted = await extractArticleContent(article.link);
          //   if (extracted) {
          //     fullContent = extracted.content;
          //     thumbnail = extracted.thumbnail || thumbnail;
          //   }
          // }

          // DBì— ì €ì¥
          const { error } = await supabaseAdmin.from('articles').insert({
            url: article.link,
            title: article.title,
            content: fullContent,
            excerpt: fullContent?.substring(0, 300) || '',
            thumbnail_url: thumbnail,
            author: article.author,
            source: new URL(feedUrl).hostname,
            published_at: article.pubDate,
            status: 'pending',
          });

          if (error) {
            console.error('Failed to insert article:', error);
          } else {
            newArticles++;
          }

          totalArticles++;

          // Rate limiting: ê¸°ì‚¬ ê°„ 500ms ëŒ€ê¸°
          await new Promise((resolve) => setTimeout(resolve, 500));
        }

        // í”¼ë“œ ê°„ 1ì´ˆ ëŒ€ê¸°
        await new Promise((resolve) => setTimeout(resolve, 1000));
      } catch (error) {
        console.error(`Failed to fetch feed ${feedUrl}:`, error);
      }
    }

    console.log(`âœ… Scraping completed: ${newArticles}/${totalArticles} new articles`);

    return NextResponse.json({
      success: true,
      totalArticles,
      newArticles,
      feeds: allFeeds.length,
    });
  } catch (error) {
    console.error('âŒ Scraping job failed:', error);
    return NextResponse.json(
      {
        error: 'Scraping failed',
        message: error instanceof Error ? error.message : 'Unknown error',
      },
      { status: 500 }
    );
  }
}
