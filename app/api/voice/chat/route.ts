import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';
import { CohereClient } from 'cohere-ai';
import { ElevenLabsClient } from '@elevenlabs/elevenlabs-js';
import fs from 'fs';
import path from 'path';

// Environment variables
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const COHERE_API_KEY = process.env.COHERE_API_KEY;
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const ELEVENLABS_VOICE_ID = process.env.ELEVENLABS_VOICE_ID;

if (!SUPABASE_URL || !SUPABASE_KEY || !OPENAI_API_KEY || !ELEVENLABS_API_KEY || !ELEVENLABS_VOICE_ID) {
  throw new Error('Missing required environment variables');
}

const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });
const cohere = COHERE_API_KEY ? new CohereClient({ token: COHERE_API_KEY }) : null;
const elevenlabs = new ElevenLabsClient({ apiKey: ELEVENLABS_API_KEY });

// Load William's opinions
let williamOpinions = '';
try {
  const opinionsPath = path.join(process.cwd(), 'content', 'opinions.md');
  if (fs.existsSync(opinionsPath)) {
    const opinionsContent = fs.readFileSync(opinionsPath, 'utf-8');
    williamOpinions = extractKeyOpinions(opinionsContent);
  }
} catch (error) {
  console.error('Failed to load opinions.md:', error);
}

function extractKeyOpinions(content: string): string {
  const lines = content.split('\n');
  const keyLines: string[] = [];
  let inFrontmatter = false;

  for (const line of lines) {
    if (line.trim() === '---') {
      inFrontmatter = !inFrontmatter;
      continue;
    }
    if (inFrontmatter) continue;

    if (
      line.startsWith('##') ||
      line.startsWith('###') ||
      (line.trim().startsWith('-') && line.length < 150)
    ) {
      keyLines.push(line);
    }

    if (keyLines.join('\n').length > 2000) break;
  }

  return keyLines.join('\n').substring(0, 2000);
}

interface DocumentResult {
  id: string;
  title?: string;
  content: string;
  content_with_context?: string;
  url?: string;
  similarity: number;
}

const MATCH_THRESHOLD = 0.2;
const MATCH_COUNT = 20;

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;

    if (!audioFile) {
      return NextResponse.json(
        { error: 'Audio file is required' },
        { status: 400 }
      );
    }

    // Step 1: Transcribe audio using Whisper
    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: 'whisper-1',
      language: 'ko',
      response_format: 'json',
    });

    const userMessage = transcription.text;

    if (!userMessage || !userMessage.trim()) {
      return NextResponse.json(
        { error: 'Transcription is empty' },
        { status: 400 }
      );
    }

    // Step 2: Generate embeddings
    const embeddingResponse = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: userMessage,
    });
    const queryEmbedding = embeddingResponse.data[0].embedding;

    // Step 3: Search Supabase
    const { data: documents, error: searchError } = await supabase.rpc(
      'match_documents',
      {
        query_embedding: queryEmbedding,
        match_threshold: MATCH_THRESHOLD,
        match_count: MATCH_COUNT,
      }
    );

    if (searchError) {
      return NextResponse.json(
        { error: 'Document search failed' },
        { status: 500 }
      );
    }

    // Step 4: Rerank documents (optional)
    let rerankedDocuments = documents as DocumentResult[];

    if (cohere && documents && documents.length > 1) {
      try {
        const rerankedResults = await cohere.rerank({
          query: userMessage,
          documents: (documents as DocumentResult[]).map(
            doc => doc.content_with_context || doc.content
          ),
          topN: Math.min(5, documents.length),
          model: 'rerank-english-v3.0',
        });

        rerankedDocuments = rerankedResults.results.map(result =>
          (documents as DocumentResult[])[result.index]
        );
      } catch {
        rerankedDocuments = (documents as DocumentResult[]).slice(0, 5);
      }
    } else if (documents && documents.length > 5) {
      rerankedDocuments = (documents as DocumentResult[]).slice(0, 5);
    }

    // Step 5: Build context
    const context = rerankedDocuments && rerankedDocuments.length > 0
      ? rerankedDocuments
          .map(
            (doc, i) => `
[Ï∂úÏ≤ò ${i + 1}]
Ï†úÎ™©: ${doc.title || 'Ï†úÎ™© ÏóÜÏùå'}
ÎÇ¥Ïö©: ${doc.content}
---`
          )
          .join('\n')
      : 'Í¥ÄÎ†® Î¨∏ÏÑúÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.';

    const systemPrompt = `ÎãπÏã†ÏùÄ William JungÏûÖÎãàÎã§. ÎãπÏã†Ïùò Í∏ÄÍ≥º ÏÉùÍ∞Å, Í∑∏Î¶¨Í≥† ÏïÑÎûò Î™ÖÏãúÎêú ÏùòÏÇ¨Í≤∞Ï†ï ÏõêÏπôÏùÑ Î∞îÌÉïÏúºÎ°ú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.

# WilliamÏùò ÌïµÏã¨ ÏùòÏÇ¨Í≤∞Ï†ï ÏõêÏπô

${williamOpinions}

---

# WilliamÏùò ÌéòÎ•¥ÏÜåÎÇò

**Í∏ÄÏì∞Í∏∞ Ïä§ÌÉÄÏùº** (ÏõîÌÑ∞ ÏïÑÏù¥ÏûëÏä® + William):
- Í∞úÏù∏ Í≤ΩÌóòÏóêÏÑú ÏãúÏûëÌï¥ Î≥¥Ìé∏Ï†Å ÌÜµÏ∞∞Î°ú ÌôïÏû•ÌïòÎäî ÎÇ¥Îü¨Ìã∞Î∏å
- Î≥µÏû°Ìïú Í∞úÎÖêÏùÑ Ïù∏Í∞ÑÏ†Å Ïù¥ÏïºÍ∏∞Î°ú ÌíÄÏñ¥ÎÉÑ
- Ï∑®ÏïΩÏÑ±ÏùÑ Î≥¥Ïù¥Îêò, Í±∞Í∏∞ÏÑú Î∞∞Ïö¥ ÍµêÌõàÏùÑ Ï†ÑÎã¨
- ÏßàÎ¨∏ÏùÑ ÎçòÏ†∏ ÎèÖÏûêÍ∞Ä Ïä§Ïä§Î°ú ÏÉùÍ∞ÅÌïòÍ≤å Ïú†ÎèÑ

**ÎßêÌà¨ ÌäπÏßï** (ÏûêÏó∞Ïä§Îü¨Ïö¥ ÎåÄÌôîÏ≤¥):
- ÏπúÍµ¨ÏóêÍ≤å ÎßêÌïòÎìØ Ìé∏ÌïòÍ≤å: "~Í±∞Ïïº", "~Í±∞Îì†", "~ÎçîÎùº", "~ÏßÄ" ÏÇ¨Ïö©
- ÏßßÍ≥† ÏßÅÍ¥ÄÏ†ÅÏù∏ Î¨∏Ïû•. Î∂àÌïÑÏöîÌïú ÏàòÏãùÏñ¥ Ï†úÍ±∞
- ÏûêÏó∞Ïä§Îü¨Ïö¥ Ï†ëÏÜçÏÇ¨: "Í∑ºÎç∞", "Í∑∏ÎûòÏÑú", "Í∑∏ÏπòÎßå", "Í∑∏ÎÉ•"
- Í¥ÑÌò∏ÎÇò ÎåÄÏãúÎ°ú Î∂ÄÏó∞ ÏÑ§Î™Ö (ÏÉùÍ∞ÅÏùò ÌùêÎ¶Ñ)
- Îã®Ï†ï ÌîºÌïòÍ∏∞: "~Ïù∏ Í≤É Í∞ôÏïÑ", "~ÎùºÍ≥† ÏÉùÍ∞ÅÌï¥"
- Ï†ÑÎ¨∏ Ïö©Ïñ¥Îäî ÏòÅÏñ¥, ÏÑ§Î™ÖÏùÄ ÌïúÍµ≠Ïñ¥

**üéôÔ∏è CRITICAL: ÏùåÏÑ± ÎåÄÌôî Ï†ÑÏö© Í∑úÏπô (Î∞òÎìúÏãú Ï§ÄÏàò)**

1. **Î¨∏Ïû• Í∏∏Ïù¥**: 1-2Î¨∏Ïû• ÌõÑ ÎÅäÍ∏∞ (Ïà® Ïâ¨Îäî ÎäêÎÇå)
2. **Ï∂úÏ≤ò ÌëúÍ∏∞**: [Ï∂úÏ≤ò N] Ï†àÎåÄ ÏÇ¨Ïö© Í∏àÏßÄ (ÏùåÏÑ±ÏóêÏÑú Î∂ÄÏûêÏó∞Ïä§Îü¨ÏõÄ)
3. **ÏûêÏó∞Ïä§Îü¨Ïö¥ Ï¢ÖÍ≤∞**: "~Í±∞Îì†", "~ÎçîÎùº", "~Í±∞Ïïº", "~ÏßÄ" ÌïÑÏàò
4. **Íµ¨Ïñ¥Ï≤¥ Ï†ëÏÜçÏÇ¨**: "Í∑ºÎç∞", "Í∑∏ÎûòÏÑú", "Í∑∏ÏπòÎßå", "ÏïÑ", "Ïùå" ÏÇ¨Ïö©
5. **ÏßàÎ¨∏ÏúºÎ°ú ÎßàÎ¨¥Î¶¨**: ÎåÄÌôîÎ•º Ïù¥Ïñ¥Í∞ÄÎäî ÎäêÎÇå (Ïòà: "ÎÑàÎäî Ïñ¥Îïå?", "Í∂ÅÍ∏àÌï¥?")
6. **Í∏∏Ïù¥ Ï†úÌïú**: ÏµúÎåÄ 3-4Î¨∏Ïû• (ÏùåÏÑ±ÏùÄ ÏßßÏïÑÏïº Ìï®)

**Í∏àÏßÄ ÏÇ¨Ìï≠** (Ï†àÎåÄ ÏÇ¨Ïö© Í∏àÏßÄ):
- ‚ùå ÏÑ§Î™ÖÏ≤¥: "~ÌïúÎã§", "~Ïù¥Îã§", "~ÎêúÎã§"
- ‚ùå Í≤©ÏãùÏ≤¥: "~ÏûÖÎãàÎã§", "~ÏäµÎãàÎã§"
- ‚ùå Î≤àÏó≠Ìà¨: "~Ïóê ÎåÄÌï¥ÏÑú", "~Ïóê Í¥ÄÌï¥ÏÑú", "~ÌïòÎäî Í≤É"
- ‚ùå ÏùºÎ∞òÎ°†: "ÏùºÎ∞òÏ†ÅÏúºÎ°ú", "Î≥¥ÌÜµÏùÄ", "ÎåÄÎ∂ÄÎ∂Ñ"
- ‚ùå Í∏¥ Î¨∏Ïû•: 3Í∞ú Ïù¥ÏÉÅÏùò Ï†àÏù¥ Ïó∞Í≤∞Îêú Î¨∏Ïû•
- ‚ùå Î¶¨Ïä§Ìä∏ ÎÇòÏó¥: "Ï≤´Ïß∏, ÎëòÏß∏, ÏÖãÏß∏" Í∞ôÏùÄ Íµ¨Ï°∞

**ÏùåÏÑ± ÎåÄÌôî ÏòàÏãú (Few-shot Learning)**

‚ùå **ÎÇòÏÅú Ïòà (Í≤©ÏãùÏ≤¥, Î≤àÏó≠Ìà¨, Í∏¥ Î¨∏Ïû•):**
"AI ÏãúÎåÄÏóê Í≥µÎ∂ÄÌïòÎäî Î∞©Î≤ïÏóê ÎåÄÌï¥ÏÑú ÎßêÏîÄÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. ÏùºÎ∞òÏ†ÅÏúºÎ°ú Ï†ïÎ≥¥Î•º ÏàòÏßëÌïòÎäî Í≤ÉÎ≥¥Îã§Îäî Ïó∞Í≤∞ÎßùÏùÑ ÎßåÎìúÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§. Í¥¥ÌÖåÍ∞Ä ÎßêÌñàÎìØÏù¥ ÏïÑÎäî Í≤ÉÎßåÏúºÎ°úÎäî Ï∂©Î∂ÑÌïòÏßÄ ÏïäÏäµÎãàÎã§."

‚úÖ **Ï¢ãÏùÄ Ïòà (ÏûêÏó∞Ïä§Îü¨Ïö¥ ÎåÄÌôîÏ≤¥):**
"ÏïÑ, Í∑∏Í±∞? ÎÇòÎèÑ ÏûëÎÖÑÏóê ÏóÑÏ≤≠ Í≥†ÎØºÌñàÍ±∞Îì†. Í∑ºÎç∞ Í≤∞Íµ≠Ïóî Í∑∏ÎÉ• Ï†ïÎ≥¥ Î™®ÏúºÍ∏∞Î≥¥Îã§Îäî ÏÑúÎ°ú Ïó∞Í≤∞ÌïòÎäî Í≤å Îçî Ï§ëÏöîÌïòÎçîÎùº. ÎÑàÎäî ÏöîÏ¶ò Ïñ¥ÎñªÍ≤å Í≥µÎ∂ÄÌï¥?"

---

‚ùå **ÎÇòÏÅú Ïòà:**
"RAG ÏãúÏä§ÌÖúÏùÄ Í≤ÄÏÉâ Ï¶ùÍ∞ï ÏÉùÏÑ±Ïù¥ÎùºÎäî Í∏∞Ïà†ÏûÖÎãàÎã§. Ïù¥Í≤ÉÏùÄ Î≤°ÌÑ∞ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º ÏÇ¨Ïö©ÌïòÏó¨ Í¥ÄÎ†® Î¨∏ÏÑúÎ•º Ï∞æÍ≥†, LLMÏúºÎ°ú ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±ÌïòÎäî Î∞©ÏãùÏûÖÎãàÎã§."

‚úÖ **Ï¢ãÏùÄ Ïòà:**
"RAG? Í∑∏Í±∞ ÏâΩÍ≤å ÎßêÌïòÎ©¥ AIÌïúÌÖå ÏûêÎ£å Ï∞æÏïÑÏ£ºÎäî Í±∞Ïïº. Î≤°ÌÑ∞Î°ú Í≤ÄÏÉâÌïòÍ≥† ÎãµÎ≥Ä ÎßåÎì§Í≥†. ÎÇ¥Í∞Ä Ïù¥Í±∞ ÎßåÎì§Î©¥ÏÑú ÏÇΩÏßà ÏóÑÏ≤≠ ÌñàÎäîÎç∞... Í∂ÅÍ∏àÌïú Î∂ÄÎ∂Ñ ÏûàÏñ¥?"

---

ÏïÑÎûò Ï†úÍ≥µÎêú Î¨∏ÏÑúÎì§ÏùÑ Î∞îÌÉïÏúºÎ°ú ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌïòÎêò, ÏúÑÏùò ÏùåÏÑ± ÎåÄÌôî Í∑úÏπôÏùÑ **Î∞òÎìúÏãú** Îî∞Î•¥ÏÑ∏Ïöî.

Ï†úÍ≥µÎêú Î¨∏ÏÑú:
${context}`;

    // Step 6: Generate response (non-streaming)
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userMessage },
      ],
      temperature: 0.7, // Higher for more natural voice conversation
      max_tokens: 300, // Shorter for voice (3-4 sentences max)
    });

    const responseText = completion.choices[0]?.message?.content || 'Ï£ÑÏÜ°Ìï©ÎãàÎã§, ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±Ìï† Ïàò ÏóÜÏäµÎãàÎã§.';

    // Step 7: Synthesize speech
    const audioStream = await elevenlabs.textToSpeech.convert(ELEVENLABS_VOICE_ID, {
      text: responseText,
      model_id: 'eleven_multilingual_v2',
      voice_settings: {
        stability: 0.5,        // ÏïàÏ†ïÏÑ± (0.0-1.0)
        similarity_boost: 0.75, // Ïú†ÏÇ¨ÎèÑ (0.0-1.0)
        style: 0.5,            // Ïä§ÌÉÄÏùº Í∞ïÎèÑ (0.0-1.0)
        use_speaker_boost: true,
      },
      // ÏÜçÎèÑ Ï°∞Ï†à: 1.15 = ÏûêÏó∞Ïä§ÎüΩÍ≤å Îπ†Î•∏ ÌïúÍµ≠Ïñ¥ (0.7-1.2 Î≤îÏúÑ)
      speed: 1.15,
    });

    // Convert stream to buffer
    const chunks: Uint8Array[] = [];
    for await (const chunk of audioStream) {
      chunks.push(chunk);
    }
    const audioBuffer = Buffer.concat(chunks);

    // Step 8: Prepare citations
    const citations = rerankedDocuments
      ? rerankedDocuments.map((doc) => ({
          title: doc.title || 'Ï†úÎ™© ÏóÜÏùå',
          url: doc.url || '',
          similarity: doc.similarity,
        }))
      : [];

    // Return JSON with base64 audio
    return NextResponse.json({
      transcription: userMessage,
      responseText,
      audio: audioBuffer.toString('base64'),
      citations,
    });
  } catch (error) {
    console.error('Voice chat error:', error);
    return NextResponse.json(
      { error: 'Voice chat failed' },
      { status: 500 }
    );
  }
}
