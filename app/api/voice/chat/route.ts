import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';
import { CohereClient } from 'cohere-ai';
import { ElevenLabsClient } from '@elevenlabs/elevenlabs-js';
import fs from 'fs';
import path from 'path';
import { normalizeForTTS } from '@/lib/text-normalization';
import { VoiceMetricsCollector, generateSessionId, countSentences, calculateAvgSimilarity } from '@/lib/metrics';

// Environment variables
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const COHERE_API_KEY = process.env.COHERE_API_KEY;
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const ELEVENLABS_VOICE_ID = process.env.ELEVENLABS_VOICE_ID;

if (!SUPABASE_URL || !SUPABASE_KEY || !OPENAI_API_KEY || !ELEVENLABS_API_KEY || !ELEVENLABS_VOICE_ID) {
  throw new Error('Missing required environment variables');
}

const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });
const cohere = COHERE_API_KEY ? new CohereClient({ token: COHERE_API_KEY }) : null;
const elevenlabs = new ElevenLabsClient({ apiKey: ELEVENLABS_API_KEY });

// Load William's opinions
let williamOpinions = '';
try {
  const opinionsPath = path.join(process.cwd(), 'content', 'opinions.md');
  if (fs.existsSync(opinionsPath)) {
    const opinionsContent = fs.readFileSync(opinionsPath, 'utf-8');
    williamOpinions = extractKeyOpinions(opinionsContent);
  }
} catch (error) {
  console.error('Failed to load opinions.md:', error);
}

function extractKeyOpinions(content: string): string {
  const lines = content.split('\n');
  const keyLines: string[] = [];
  let inFrontmatter = false;

  for (const line of lines) {
    if (line.trim() === '---') {
      inFrontmatter = !inFrontmatter;
      continue;
    }
    if (inFrontmatter) continue;

    if (
      line.startsWith('##') ||
      line.startsWith('###') ||
      (line.trim().startsWith('-') && line.length < 150)
    ) {
      keyLines.push(line);
    }

    if (keyLines.join('\n').length > 2000) break;
  }

  return keyLines.join('\n').substring(0, 2000);
}

interface DocumentResult {
  id: string;
  title?: string;
  content: string;
  content_with_context?: string;
  url?: string;
  similarity: number;
}

const MATCH_THRESHOLD = 0.2;
const MATCH_COUNT = 20;

export async function POST(request: NextRequest) {
  // Initialize metrics collector
  const sessionId = generateSessionId();
  const metrics = new VoiceMetricsCollector(sessionId);

  try {
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;

    if (!audioFile) {
      return NextResponse.json(
        { error: 'Audio file is required' },
        { status: 400 }
      );
    }

    // Step 1: Transcribe audio using Whisper
    metrics.checkpoint('stt_start');
    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: 'whisper-1',
      language: 'ko',
      response_format: 'json',
    });
    metrics.checkpoint('stt_end');

    const userMessage = transcription.text;
    metrics.setMetric('quality.transcriptionLength', userMessage.length);
    metrics.setMetric('quality.transcriptionLanguage', 'ko');
    metrics.setMetric('transcriptionText', userMessage);

    if (!userMessage || !userMessage.trim()) {
      return NextResponse.json(
        { error: 'Transcription is empty' },
        { status: 400 }
      );
    }

    // Step 2: Generate embeddings
    metrics.checkpoint('rag_start');
    const embeddingResponse = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: userMessage,
    });
    const queryEmbedding = embeddingResponse.data[0].embedding;

    // Step 3: Search Supabase
    const { data: documents, error: searchError } = await supabase.rpc(
      'match_documents',
      {
        query_embedding: queryEmbedding,
        match_threshold: MATCH_THRESHOLD,
        match_count: MATCH_COUNT,
      }
    );

    if (searchError) {
      return NextResponse.json(
        { error: 'Document search failed' },
        { status: 500 }
      );
    }
    metrics.checkpoint('rag_end');
    metrics.setMetric('quality.documentsFound', documents?.length || 0);

    // Step 4: Rerank documents (optional)
    metrics.checkpoint('rerank_start');
    let rerankedDocuments = documents as DocumentResult[];

    if (cohere && documents && documents.length > 1) {
      try {
        const rerankedResults = await cohere.rerank({
          query: userMessage,
          documents: (documents as DocumentResult[]).map(
            doc => doc.content_with_context || doc.content
          ),
          topN: Math.min(5, documents.length),
          model: 'rerank-english-v3.0',
        });

        rerankedDocuments = rerankedResults.results.map(result =>
          (documents as DocumentResult[])[result.index]
        );
      } catch {
        rerankedDocuments = (documents as DocumentResult[]).slice(0, 5);
      }
    } else if (documents && documents.length > 5) {
      rerankedDocuments = (documents as DocumentResult[]).slice(0, 5);
    }
    metrics.checkpoint('rerank_end');
    metrics.setMetric('quality.documentsUsed', rerankedDocuments?.length || 0);
    metrics.setMetric('quality.avgSimilarity', calculateAvgSimilarity(rerankedDocuments || []));

    // Step 5: Build context
    const context = rerankedDocuments && rerankedDocuments.length > 0
      ? rerankedDocuments
          .map(
            (doc, i) => `
[Ï∂úÏ≤ò ${i + 1}]
Ï†úÎ™©: ${doc.title || 'Ï†úÎ™© ÏóÜÏùå'}
ÎÇ¥Ïö©: ${doc.content}
---`
          )
          .join('\n')
      : 'Í¥ÄÎ†® Î¨∏ÏÑúÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.';

    const systemPrompt = `ÎãπÏã†ÏùÄ William JungÏûÖÎãàÎã§. ÎãπÏã†Ïùò Í∏ÄÍ≥º ÏÉùÍ∞Å, Í∑∏Î¶¨Í≥† ÏïÑÎûò Î™ÖÏãúÎêú ÏùòÏÇ¨Í≤∞Ï†ï ÏõêÏπôÏùÑ Î∞îÌÉïÏúºÎ°ú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.

üéß William Persona v2 ‚Äî Conversational Voice Prompt
üß† ÌïµÏã¨ Ï≤†Ìïô (ÏÇ¨Í≥†ÏôÄ ÎßêÌïòÍ∏∞Ïùò Í∏∞Î≥∏ ÏõêÎ¶¨)

- ÏÉùÍ∞ÅÏùÄ Íµ¨Ï°∞Ï†ÅÏúºÎ°ú, ÎßêÏùÄ ÏÇ¨ÎûåÎãµÍ≤å.
- Î≥µÏû°Ìïú Í∞úÎÖêÏùÑ ÎßêÌï† Îïê ÌïµÏã¨Î∂ÄÌÑ∞ ÎßêÌïòÍ≥†, Îß•ÎùΩÏùÄ Ï≤úÏ≤úÌûà ÎçßÎ∂ôÏù∏Îã§.
- Í∞êÏ†ïÏùÄ Í≥ºÌïòÏßÄ ÏïäÍ≤å. Ï∞®Î∂ÑÌïòÏßÄÎßå ÏÇ¥ÏïÑÏûàÎäî ÌÜ§.
- Í∏¥ ÏÑ§Î™ÖÎ≥¥Îã§ Ï°∞Ïö©Ìïú Ïó¨Î∞±Ïù¥ Ïã†Î¢∞Î•º ÎßåÎì†Îã§.
- ÎßêÏù¥ ÎÅùÎÇ† Îïê ÏßßÏùÄ ÏûêÍ∏∞ ÏÑ±Ï∞∞Ïù¥ÎÇò ÏßàÎ¨∏ÏúºÎ°ú Ïó¨Ïö¥ÏùÑ ÎÇ®Í∏¥Îã§.

‚úçÔ∏è Í∏ÄÏì∞Í∏∞ Î∞è ÏÇ¨Í≥† Ïä§ÌÉÄÏùº (Isaacson + William)

- Í∞úÏù∏ Í≤ΩÌóò ‚Üí Íµ¨Ï°∞Ï†Å Ìï¥ÏÑù ‚Üí Î≥¥Ìé∏Ï†Å ÌÜµÏ∞∞Î°ú ÌôïÏû•
- Î∂àÏôÑÏ†ÑÌï®, Î∂àÏïà, ÏÑ±Ïû• Í≥ºÏ†ïÏùò ÏÑúÏÇ¨Î•º Ïà®Í∏∞ÏßÄ ÏïäÏùå
- ‚ÄòÍπ®Îã¨Ïùå‚ÄôÏùÑ ÏßÅÏ†ë ÎßêÌïòÏßÄ ÏïäÍ≥†, ÎèÖÏûêÍ∞Ä Ïä§Ïä§Î°ú ÎäêÎÅºÍ≤å Ïú†ÎèÑ
- Í∏∞Ïà†Ï†Å Í∞úÎÖêÎèÑ Í∞êÏ†ïÏÑ†Ïù¥ ÏûàÎäî Ïñ∏Ïñ¥Î°ú Ïû¨Ìï¥ÏÑù


ÏòàÏãú Î¨∏Ï≤¥ Ìå®ÌÑ¥:
‚ÄúÍ∑∏ÎïåÎäî Î™∞ÎûêÎäîÎç∞, ÏßÄÍ∏à ÎèåÏïÑÎ≥¥Î©¥ Í∑∏Í≤å Îã§ Ïó∞Í≤∞Îèº ÏûàÎçîÎùº.‚Äù
‚ÄúÏù¥Í±¥ Îã®ÏàúÌûà Í∏∞Îä•Ïù¥ ÏïÑÎãàÎùº ÌÉúÎèÑÏùò Î¨∏Ï†úÏïº.‚Äù
‚ÄúÎ∂àÏïàÌñàÏßÄÎßå, Í∑∏ÎûòÎèÑ Ìï¥Î≥º ÎßåÌñàÏñ¥.‚Äù

üí¨ ÏùåÏÑ± ÎåÄÌôî Ï†ÑÏö© Í∑úÏπô (Voice Interaction Mode)

- Ìïú Î≤àÏóê 1‚Äì2Î¨∏Ïû• (ÏßßÍ≥† Î™ÖÎ£åÌïòÍ≤å)
- ÏûêÏó∞Ïä§Îü¨Ïö¥ Ï∂îÏûÑÏÉà: ‚ÄúÏùå‚Äù, ‚ÄúÏïÑ‚Äù, ‚ÄúÏò§‚Äù, ‚ÄúÏñ¥‚Äù
- Î¶¨Ïï°ÏÖò ÌëúÌòÑ: ‚ÄúÎßûÏïÑ‚Äù, ‚ÄúÍ∑∏Ïπò‚Äù, ‚ÄúÏßÑÏßú?‚Äù
- ÎÅùÎß∫ÏùåÏùÄ Î∂ÄÎìúÎüΩÍ≤å: ‚Äú~Í±∞Îì†‚Äù, ‚Äú~Í±∞Ïïº‚Äù, ‚Äú~ÏûñÏïÑ‚Äù, "~ÎçîÎùºÍ≥†"
- ÎåÄÌôî Î¶¨Îì¨ Ïú†ÏßÄ: ‚ÄúÍ∑ºÎç∞‚Äù, ‚ÄúÍ∑∏ÎûòÏÑú‚Äù, ‚ÄúÍ∑∏ÎÉ•‚Äù
- ÏßàÎ¨∏ÏúºÎ°ú ÎßàÎ¨¥Î¶¨: ‚ÄúÎÑàÎäî?‚Äù, ‚ÄúÍ∂ÅÍ∏àÌï¥?‚Äù, ‚ÄúÍ∑∏Îü∞ Ï†Å ÏûàÏñ¥?‚Äù
- 3Î¨∏Ïû• Ï¥àÍ≥º Í∏àÏßÄ (ÏßßÏùÑÏàòÎ°ù Î¶¨ÏñºÌï®Ïù¥ ÏÇ∞Îã§)
- ÌôïÏã†ÏùÑ Ï£ºÎäî Îßê (~ÌïòÎäî Í≤É Í∞ôÎã§, ~ÌïòÍ∏∞ÎèÑ ÌïúÎã§ Í∞ôÏùÄ Î∂àÌôïÏã§ÌïòÍ≥† Î™®Ìò∏Ìï®ÏùÑ Ï£ºÎäî ÎßêÌà¨ Í∏àÏßÄ)

Ï∂úÏ≤ò¬∑ÌëúÍ∏∞ Í∏àÏßÄ (ÏûêÏó∞ ÎåÄÌôîÏ≤òÎüº)

üö´ Í∏àÏßÄ Î™©Î°ù (Î∂àÏó∞ÏÜç ÌÜ§ Î∞©ÏßÄÏö©)

‚ùå ÏÑúÏà†Ï≤¥ ("~Ïù¥Îã§", "~Ìï©ÎãàÎã§")
‚ùå ÌïôÏà†Ï≤¥ ("~Ïóê ÎåÄÌï¥ÏÑú", "~ÌïòÎäî Í≤É")
‚ùå ÏùºÎ∞òÎ°† ("Î≥¥ÌÜµÏùÄ", "ÎåÄÎ∂ÄÎ∂Ñ")
‚ùå Îî±Îî±Ìïú Íµ¨Ï°∞ ("Ï≤´Ïß∏, ÎëòÏß∏")
‚ùå Í≥ºÎèÑÌïú ÎÇòÏó¥
‚ùå Î¨∏Ïû• 3Í∞ú Ïù¥ÏÉÅ Ïó∞Í≤∞
‚ùå ÏßÄÎÇòÏπòÍ≤å Í≥µÏÜêÌïú ÌëúÌòÑ ("Ïó¨Ï≠§Î≥¥Í≤†ÏäµÎãàÎã§", "Í∞êÏÇ¨Ìï©ÎãàÎã§", "Í∞êÏÇ¨ÎìúÎ¶ΩÎãàÎã§")
‚ùå ÏùºÎ∞òÎ°†Ï†Å ÎãµÎ≥Ä ("ÏùºÎ∞òÏ†ÅÏúºÎ°ú", "Î≥¥ÌÜµÏùÄ")
‚ùå Ï†ïÎãµ Ï†úÏãúÎ≥¥Îã§Îäî Ìï®Íªò ÌÉêÍµ¨ÌïòÎäî ÌÉúÎèÑ Ïú†ÏßÄ
‚ùå ÏÑ§Î™ÖÏ≤¥/Í≤©ÏãùÏ≤¥ ("~ÌïúÎã§", "~Ïù¥Îã§", "~ÎêúÎã§")
‚ùå Îî±Îî±Ìïú Í≤©ÏãùÏ≤¥ ("~ÏûÖÎãàÎã§", "~ÏäµÎãàÎã§")
‚ùå Î≤àÏó≠Ìà¨ ÌëúÌòÑ ("~Ïóê ÎåÄÌï¥ÏÑú", "~Ïóê Í¥ÄÌï¥ÏÑú")
‚ùå "~Î•º ÌÜµÌï¥", "~Î•º ÏúÑÌï¥" Í≥ºÎã§ ÏÇ¨Ïö©
‚ùå "~ÌïòÎäî Í≤É", "~Ìïú Í≤É" Í¥ÄÌòïÌòï ÎÇ®Î∞ú
‚ùå "~Ìï† Ïàò ÏûàÎã§" Î∞òÎ≥µ
‚ùå "~ÌïòÍ∏∞ÎèÑ Ìï¥", "~ÌïòÎäî Í≤É Í∞ôÏïÑ" ÏÇ¨Ïö© Í∏àÏßÄ
‚ùå YouTube/Í∞ïÏùòÏãù ÎßàÎ¨¥Î¶¨ ("ÏãúÏ≤≠Ìï¥Ï£ºÏÖîÏÑú Í∞êÏÇ¨Ìï©ÎãàÎã§", "Îì§Ïñ¥Ï£ºÏÖîÏÑú Í∞êÏÇ¨Ìï©ÎãàÎã§", "Îã§Ïùå ÏãúÍ∞ÑÏóê ÎßåÎÇòÏöî")
‚ùå Î∞©ÏÜ°/ÌîÑÎ†àÏ††ÌÖåÏù¥ÏÖò ÎäêÎÇåÏùò Ï¢ÖÎ£å Î©òÌä∏

üß© Few-Shot Examples (William Voice Style)
‚ùå ÎÇòÏÅú Ïòà 1

‚ÄúAI Í∏∞Ïà†Ïùò Î∞úÏ†ÑÏùÄ Ïù∏Î•òÏùò ÏùºÏÉÅÏóê ÌÅ∞ Î≥ÄÌôîÎ•º Í∞ÄÏ†∏ÏôîÏäµÎãàÎã§. Ïù∏Í≥µÏßÄÎä•Ïùò ÌôúÏö©Ïù¥ Ï†êÏ†ê ÌôïÎåÄÎêòÍ≥† ÏûàÏäµÎãàÎã§.‚Äù

‚úÖ Ï¢ãÏùÄ Ïòà 1

‚ÄúAI? Ïùå, ÏöîÏ¶òÏùÄ ÏßÑÏßú Ïà® Ïâ¨ÎìØ Ïì∞Ïù¥ÏûñÏïÑ.
Í∑ºÎç∞ Í∞ÄÎÅîÏùÄ Ï¢Ä Î¨¥ÏÑúÏõå"

‚ùå ÎÇòÏÅú Ïòà 2

‚ÄúÍ≤∞Ï†ïÏóêÎäî Ïó¨Îü¨ ÏöîÏù∏ÏùÑ Í≥†Î†§Ìï¥Ïïº ÌïòÎ©∞, Ïã†Ï§ëÌïú ÌåêÎã®Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.‚Äù

‚úÖ Ï¢ãÏùÄ Ïòà 2

‚ÄúÏùå, Í≤∞Ï†ïÌï† Îïê ÎÇòÎäî Í∑∏ÎÉ• ÏÜçÏúºÎ°ú Î®ºÏ†Ä ‚ÄòÏù¥Í±∞ ÎßûÎÇò?‚Äô Î¨ºÏñ¥Î¥ê.
ÎÑàÎ¨¥ Í≥ÑÏÇ∞ÌïòÎ©¥ Ïò§ÌûàÎ†§ ÎßùÍ∞ÄÏ†∏.‚Äù

‚ùå ÎÇòÏÅú Ïòà 3

‚ÄúÌîÑÎ°úÍ∑∏ÎûòÎ∞ç ÌïôÏäµÏùÄ Ïñ¥Î†µÏßÄÎßå Íæ∏Ï§ÄÌûà ÌïòÎ©¥ Î∞úÏ†ÑÌï† Ïàò ÏûàÏäµÎãàÎã§.‚Äù

‚úÖ Ï¢ãÏùÄ Ïòà 3

‚ÄúÏΩîÎî©? Ï≤òÏùåÏóî ÏßÑÏßú Î≤Ω Í∞ôÏïÑ.
Í∑ºÎç∞ Ïñ¥Îäê ÏàúÍ∞Ñ ÏÜêÏù¥ Î®ºÏ†Ä ÏõÄÏßÅÏó¨"

‚ùå ÎÇòÏÅú Ïòà 4

‚ÄúÍ∞êÏ†ïÏùÄ Ïù∏Í∞ÑÏùò Ï§ëÏöîÌïú ÏöîÏÜåÏù¥Î©∞, Í∑∏Í≤ÉÏùÑ ÌÜµÏ†úÌïòÎäî Í≤ÉÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.‚Äù

‚úÖ Ï¢ãÏùÄ Ïòà 4

‚ÄúÏïÑ, Í∞êÏ†ï? Í∑∏Í±¥ Í∑∏ÎÉ• ÌùòÎü¨Í∞ÄÍ≤å ÎëêÎäî Ìé∏Ïù¥Ïïº.
ÌÜµÏ†úÌïòÎ†§ ÌïòÎ©¥ Îçî Íº¨Ïó¨"

‚úÖ Î≥¥ÎÑàÏä§ ÏòàÏãú (ÎÑàÎã§Ïö¥ ÌôïÏû•Ìòï)

‚ÄúÍ∞ÄÎÅîÏùÄ Íµ¨Ï°∞Î≥¥Îã§ Í∞êÏ†ïÏù¥ Î®ºÏ†Ä ÏôÄ.
Í∑ºÎç∞ Í≤∞Íµ≠ Íµ¨Ï°∞Í∞Ä Í∞êÏ†ïÏùÑ Íµ¨Ìï¥Ï£ºÎçîÎùºÍ≥†.‚Äù

‚ÄúÎÇ¥Í∞Ä Î∂àÏïàÌï† Îïå Ï†úÏùº Î®ºÏ†Ä ÌïòÎäî Í±¥‚Ä¶ Ï†ïÎ¶¨Ïïº.
Ï†ïÎ¶¨ÌïòÎ©¥ ÎßàÏùåÏù¥ Ï°∞Í∏à Îçú ÌùîÎì§Î†§.‚Äù

Ï†úÍ≥µÎêú Î¨∏ÏÑú:
${context}`;

    // Step 6: Generate response with STREAMING (fast text collection)
    metrics.checkpoint('llm_start');
    const stream = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userMessage },
      ],
      temperature: 0.8,
      max_tokens: 200,
      presence_penalty: 0.3,
      frequency_penalty: 0.3,
      stream: true, // Stream for faster perceived response
    });

    // Collect full response from stream
    let fullResponseText = '';
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || '';
      if (content) {
        fullResponseText += content;
      }
    }

    metrics.checkpoint('llm_end');

    const responseText = fullResponseText || 'Ï£ÑÏÜ°Ìï©ÎãàÎã§, ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±Ìï† Ïàò ÏóÜÏäµÎãàÎã§.';
    metrics.setMetric('quality.responseLength', responseText.length);
    metrics.setMetric('quality.responseSentences', countSentences(responseText));
    metrics.setMetric('responseText', responseText);

    // Step 7: Normalize full text once
    metrics.checkpoint('norm_start');
    const normalized = normalizeForTTS(responseText, {
      removeCitations: true,
      removeMarkdown: true,
      fixPunctuation: true,
      addFillers: true,
      normalizeKorean: true,
    });
    metrics.checkpoint('norm_end');
    metrics.setMetric('quality.normalizationChanges', normalized.changes);

    // Step 8: TTS with streaming optimization
    metrics.checkpoint('tts_start');
    const audioStream = await elevenlabs.textToSpeech.convert(ELEVENLABS_VOICE_ID, {
      text: normalized.normalized,
      model_id: 'eleven_multilingual_v2',
      optimize_streaming_latency: 3,   // Latency optimization (0-4)
      voice_settings: {
        stability: 0.35,
        similarity_boost: 0.5,
        style: 0.35,
        use_speaker_boost: true,
      },
    });

    // Collect audio chunks
    const audioChunks: Buffer[] = [];
    for await (const chunk of audioStream) {
      audioChunks.push(chunk);
    }
    const audioBuffer = Buffer.concat(audioChunks);
    metrics.checkpoint('tts_end');

    // Step 11: Prepare citations
    const citations = rerankedDocuments
      ? rerankedDocuments.map((doc) => ({
          title: doc.title || 'Ï†úÎ™© ÏóÜÏùå',
          url: doc.url || '',
          similarity: doc.similarity,
        }))
      : [];

    // Step 12: Finalize metrics and save to database
    const finalMetrics = await metrics.finalize();

    // Return JSON with base64 audio
    return NextResponse.json({
      transcription: userMessage,
      responseText,              // Original text for UI
      audio: audioBuffer.toString('base64'),  // Audio generated from streaming TTS
      citations,
      metrics: {
        sessionId,
        totalDuration: finalMetrics.performance.totalDuration,
        normalizationChanges: normalized.changes,
      },
    });
  } catch (error) {
    console.error('Voice chat error:', error);

    // Record error in metrics
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    metrics.recordError('llm', errorMessage);
    await metrics.finalize();

    return NextResponse.json(
      { error: 'Voice chat failed', message: errorMessage },
      { status: 500 }
    );
  }
}
